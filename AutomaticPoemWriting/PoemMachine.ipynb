{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 一、实验目的\n",
    "1. 理解和掌握循环神经网络概念及在深度学习框架中的实现。\n",
    "2. 掌握使用深度学习框架进行文本生成任务的基本流程：如数据读取、构造网络、训练和预测等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 实验要求\n",
    "1. 基于 Python 语言和任意一种深度学习框架（实验指导书中使用 Pytorch 框架\n",
    "进行介绍） ，完成数据读取、网络设计、网络构建、模型训练和模型测试等过\n",
    "程，最终实现一个可以自动写诗的程序。网络结构设计要有自己的方案，不\n",
    "能与实验指导书完全相同。\n",
    "2. 随意给出首句，如给定“湖光秋月两相和”，输出模型续写的诗句。也可以根\n",
    "据自己的兴趣，进一步实现写藏头诗（不做要求） 。要求输出的诗句尽可能地\n",
    "满足汉语语法和表达习惯。实验提供预处理后的唐诗数据集，包含 57580 首\n",
    "唐诗（在课程网站下载） ，也可以使用其他唐诗数据集。\n",
    "3. 按规定时间在课程网站提交实验报告、代码以及 PPT。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、实验原理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare\n",
    "'''\n",
    "    data_loader  数据加载器\n",
    "    ix2word      序号到词的映射\n",
    "    word2ix      词到序号的映射\n",
    "'''\n",
    "\n",
    "dataset = np.load('./data/tang.npz', allow_pickle=True)\n",
    "data = dataset['data']\n",
    "ix2word = dataset['ix2word'].item()\n",
    "word2ix = dataset['word2ix'].item()\n",
    "data = torch.from_numpy(data)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# class Poetry(nn.Module):\n",
    "#     def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "#         super(Poetry, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "#     def forward(self, input, hidden=None):\n",
    "\n",
    "#         batch_size, seq_len = input.size()\n",
    "\n",
    "#         if hidden is None:\n",
    "#             h_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "#             c_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "#         else:\n",
    "#             h_0, c_0 = hidden\n",
    "\n",
    "#         embeds = self.embedding(input)\n",
    "#         output, hidden = self.lstm(embeds, (h_0, c_0))\n",
    "#         output = self.fc(output)\n",
    "#         output = output.reshape(batch_size * seq_len, -1)\n",
    "#         return output, hidden\n",
    "\n",
    "class Poetry(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.5, pretrained_embeddings=None):\n",
    "        super(Poetry, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(pretrained_embeddings)\n",
    "            self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        batch_size, seq_len = input.size()\n",
    "\n",
    "        if hidden is None:\n",
    "            h_0 = input.data.new(2, batch_size, self.hidden_dim).zero_().float()\n",
    "            c_0 = input.data.new(2, batch_size, self.hidden_dim).zero_().float()\n",
    "        else:\n",
    "            h_0, c_0 = hidden\n",
    "\n",
    "        embeds = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.lstm(embeds, (h_0, c_0))\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        output = output.reshape(batch_size * seq_len, -1)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyperPara import paraList\n",
    "# hyper-parameters in paraList\n",
    "\n",
    "model = Poetry(\n",
    "    len(word2ix),\n",
    "    embedding_dim=paraList.embedding_dim,\n",
    "    hidden_dim=paraList.hidden_dim\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=paraList.lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_meter = 0\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "def train(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    loss_meter = 0\n",
    "\n",
    "    loop = tqdm(data_loader, total=len(data_loader))  # 使用 tqdm 创建进度条\n",
    "    loop.set_description()\n",
    "\n",
    "    for i, data in enumerate(loop):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.long()\n",
    "        input, target = data[:, :-1], data[:, 1:]\n",
    "        output, _ = model(input)\n",
    "        loss = criterion(output, target.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter += loss.item()\n",
    "        loop.set_description(f'Training Epoch [{i+1}/{len(data_loader)}]')\n",
    "        loop.set_postfix(loss=loss_meter/(i+1))\n",
    "\n",
    "\n",
    "def generate(model, start_words, ix2words, word2ix, max_length=100):\n",
    "    model.train()\n",
    "    result = list(start_words)\n",
    "    start_words_len = len(start_words)\n",
    "    input = torch.Tensor([word2ix['<START>']]).view(1, 1).long()\n",
    "    hidden = None\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(max_length):\n",
    "            output, hidden = model(input, hidden)\n",
    "            if i < start_words_len:\n",
    "                w = result[i]\n",
    "                input = torch.Tensor([word2ix[w]]).view(1, 1).long()\n",
    "            else:\n",
    "                top_index = output.data.topk(1)[1].item()\n",
    "                w = ix2words[top_index]\n",
    "                result.append(w)\n",
    "                input = torch.Tensor([top_index]).view(1, 1).long()\n",
    "            if w == '<EOP>':\n",
    "                del result[-1]\n",
    "                break\n",
    "\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3599/3599]: 100%|██████████| 3599/3599 [19:56<00:00,  3.01it/s, loss=2.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Say:  苟利国家生死以，不知不得不可知。\n",
      "====> Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3599/3599]: 100%|██████████| 3599/3599 [20:31<00:00,  2.92it/s, loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Say:  苟利国家生死以，不知不得无人情。不知不得无人事，不见金衣不可知。不知不得无人事，不见金衣不可知。\n",
      "====> Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3599/3599]: 100%|██████████| 3599/3599 [20:22<00:00,  2.94it/s, loss=2.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Say:  苟利国家生死以，不知天子不能知。一时不得无人事，不得无人不得知。不得不知无事事，不知何处不知君。\n",
      "====> Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3599/3599]: 100%|██████████| 3599/3599 [18:09<00:00,  3.30it/s, loss=2.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Say:  苟利国家生死以，不知何处不能知。不知此事无人事，不得无人不得知。不得不知无事事，不知何处是君心。\n",
      "====> Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3599/3599]: 100%|██████████| 3599/3599 [3:02:09<00:00,  3.04s/it, loss=2.27]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Say:  苟利国家生死以，不知无事不能知。不知不得无人事，不是人间不可知。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "for epoch in range(EPOCH):\n",
    "    print('====> Epoch: {}'.format(epoch+1))\n",
    "    train(model, data_loader, optimizer, criterion)\n",
    "    print('====> Say: ', end=' ')\n",
    "    print(generate(model, '苟利国家生死以', ix2word, word2ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Acrostic_poetry_generator(start_word, ix2word, word2ix):\n",
    "    # build model\n",
    "    model = Poetry(len(word2ix), embedding_dim=paraList.embedding_dim, hidden_dim=paraList.hidden_dim)\n",
    "    model.load_state_dict(torch.load(start_word))\n",
    "\n",
    "    # save head\n",
    "    result = []\n",
    "    start_word_len = len(start_word)\n",
    "\n",
    "    # first word tag\n",
    "    input = (torch.Tensor([word2ix['<START>']]).view(1, 1).long())\n",
    "    hidden = None\n",
    "\n",
    "    index = 0\n",
    "    pre_word = '<START>'\n",
    "\n",
    "    for i in range(paraList.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        top_index = output.data[0].topk(1)[1][0].item()\n",
    "        w = ix2word[top_index]\n",
    "\n",
    "        # generate head\n",
    "        if (pre_word in {u'。', u'!', '<START>'}):\n",
    "            if index == start_word_len:\n",
    "                break\n",
    "            else:\n",
    "                w = start_word[index]\n",
    "                index += 1\n",
    "                input = (input.data.new([word2ix[w]])).view(1, 1)\n",
    "        else:\n",
    "            input = (input.data.new([word2ix[w]])).view(1, 1)\n",
    "        result.append(w)\n",
    "        pre_word = w\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to ./saved_models/model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = './saved_models'\n",
    "    # build folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_save_path = os.path.join(save_dir, 'model.pth')\n",
    "# save model\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "print(f\"model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetry(\n",
      "  (embedding): Embedding(8293, 300)\n",
      "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (fc): Linear(in_features=256, out_features=8293, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
